#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¨ Advanced CSS Classes Extractor & Analyzer
Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSS Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„ØªØ±Ø§ÙƒØ¨
"""

import re
import json
import os
from collections import defaultdict, OrderedDict
from pathlib import Path
from datetime import datetime

class AdvancedCSSExtractor:
    def __init__(self):
        self.global_classes = {}  # Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ù…Ø¹ ØªØ¹Ø±ÙŠÙØ§ØªÙ‡Ø§
        self.duplicate_classes = defaultdict(list)  # Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        self.file_hierarchy = {}  # Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
        self.class_sources = defaultdict(set)  # Ù…ØµØ§Ø¯Ø± ÙƒÙ„ ÙƒÙ„Ø§Ø³
        self.merged_definitions = {}  # Ø§Ù„ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
        
    def extract_css_with_definitions(self, css_content, source_file=""):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ CSS Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ø¨Ù†ÙŠØ©
        css_content = re.sub(r'/\*.*?\*/', '', css_content, flags=re.DOTALL)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ @import statements
        imports = re.findall(r'@import\s+(?:url\()?["\']?([^"\';\)]+)["\']?\)?[^;]*;', css_content)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ @media queries
        media_queries = re.findall(r'(@media[^{]+\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})', css_content, re.DOTALL)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
        # Ù†Ù…Ø· Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© Ù„Ù„Ù‚ÙˆØ§Ø¹Ø¯
        rules_pattern = r'([^{}@]+)\s*\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}'
        rules = re.findall(rules_pattern, css_content, re.DOTALL)
        
        extracted_data = {
            'source_file': source_file,
            'imports': imports,
            'media_queries': media_queries,
            'classes': {},
            'ids': {},
            'elements': {},
            'complex_selectors': {},
            'statistics': {
                'total_selectors': 0,
                'classes_count': 0,
                'ids_count': 0,
                'elements_count': 0
            }
        }
        
        for selector_group, properties in rules:
            selector_group = selector_group.strip()
            properties = properties.strip()
            
            if not selector_group or not properties:
                continue
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ø­Ø¯Ø¯Ø§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
            selectors = [s.strip() for s in selector_group.split(',') if s.strip()]
            
            for selector in selectors:
                extracted_data['statistics']['total_selectors'] += 1
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯
                self.analyze_selector_advanced(selector, properties, extracted_data, source_file)
        
        return extracted_data
    
    def analyze_selector_advanced(self, selector, properties, extracted_data, source_file):
        """ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ø­Ø¯Ø¯Ø§Øª Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ¯Ø§Ø®Ù„"""
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø­Ø¯Ø¯
        clean_selector = re.sub(r'\s+', ' ', selector.strip())
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯
        selector_info = {
            'selector': clean_selector,
            'properties': self.parse_properties_advanced(properties),
            'source': source_file,
            'specificity': self.calculate_specificity(clean_selector),
            'type': self.determine_selector_type(clean_selector)
        }
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª
        class_matches = re.findall(r'\.([a-zA-Z0-9_-]+)', clean_selector)
        for class_name in class_matches:
            if class_name not in extracted_data['classes']:
                extracted_data['classes'][class_name] = []
            extracted_data['classes'][class_name].append(selector_info)
            extracted_data['statistics']['classes_count'] += 1
            
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ø³ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø§Ù…
            self.register_class_globally(class_name, selector_info)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª
        id_matches = re.findall(r'#([a-zA-Z0-9_-]+)', clean_selector)
        for id_name in id_matches:
            if id_name not in extracted_data['ids']:
                extracted_data['ids'][id_name] = []
            extracted_data['ids'][id_name].append(selector_info)
            extracted_data['statistics']['ids_count'] += 1
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ±
        element_matches = re.findall(r'\b(a|div|span|table|tr|td|th|img|input|button|form|body|html|h[1-6]|p|ul|li|ol|iframe|select|textarea)\b', clean_selector)
        for element in element_matches:
            if element not in extracted_data['elements']:
                extracted_data['elements'][element] = []
            extracted_data['elements'][element].append(selector_info)
            extracted_data['statistics']['elements_count'] += 1
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
        if self.is_complex_selector(clean_selector):
            if clean_selector not in extracted_data['complex_selectors']:
                extracted_data['complex_selectors'][clean_selector] = []
            extracted_data['complex_selectors'][clean_selector].append(selector_info)
    
    def register_class_globally(self, class_name, selector_info):
        """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ø³ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø§Ù… Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±"""
        
        if class_name not in self.global_classes:
            self.global_classes[class_name] = []
        
        self.global_classes[class_name].append(selector_info)
        self.class_sources[class_name].add(selector_info['source'])
        
        # ÙØ­Øµ Ø§Ù„ØªÙƒØ±Ø§Ø±
        if len(self.global_classes[class_name]) > 1:
            self.duplicate_classes[class_name] = self.global_classes[class_name]
    
    def parse_properties_advanced(self, properties_str):
        """ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ø®ØµØ§Ø¦Øµ CSS"""
        properties = OrderedDict()
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø®ØµØ§Ø¦Øµ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
        prop_pattern = r'([^:;]+):\s*([^;]+(?:;[^:;]*)*)'
        matches = re.findall(prop_pattern, properties_str)
        
        for prop, value in matches:
            prop = prop.strip()
            value = value.strip().rstrip(';')
            
            if prop and value:
                properties[prop] = {
                    'value': value,
                    'important': '!important' in value,
                    'variables': re.findall(r'var\([^)]+\)', value),
                    'functions': re.findall(r'(\w+)\([^)]*\)', value)
                }
        
        return properties
    
    def calculate_specificity(self, selector):
        """Ø­Ø³Ø§Ø¨ specificity Ù„Ù„Ù…Ø­Ø¯Ø¯"""
        # Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª
        ids = len(re.findall(r'#[a-zA-Z0-9_-]+', selector))
        
        # Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª ÙˆØ§Ù„Ø®ØµØ§Ø¦Øµ ÙˆØ§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø²Ø§Ø¦ÙØ©
        classes = len(re.findall(r'\.[a-zA-Z0-9_-]+', selector))
        attributes = len(re.findall(r'\[[^\]]+\]', selector))
        pseudo_classes = len(re.findall(r':[a-zA-Z0-9_-]+(?!\:)', selector))
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙˆØ§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø²Ø§Ø¦ÙØ© Ù„Ù„Ø¹Ù†Ø§ØµØ±
        elements = len(re.findall(r'\b(a|div|span|table|tr|td|th|img|input|button|form|body|html|h[1-6]|p|ul|li|ol|iframe|select|textarea)\b', selector))
        pseudo_elements = len(re.findall(r'::[a-zA-Z0-9_-]+', selector))
        
        return {
            'ids': ids,
            'classes': classes + attributes + pseudo_classes,
            'elements': elements + pseudo_elements,
            'score': ids * 100 + (classes + attributes + pseudo_classes) * 10 + (elements + pseudo_elements)
        }
    
    def determine_selector_type(self, selector):
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­Ø¯Ø¯"""
        if '@' in selector:
            return 'at-rule'
        elif '::' in selector:
            return 'pseudo-element'
        elif ':' in selector:
            return 'pseudo-class'
        elif '[' in selector and ']' in selector:
            return 'attribute'
        elif '#' in selector:
            return 'id'
        elif '.' in selector:
            return 'class'
        elif any(op in selector for op in ['+', '>', '~']):
            return 'combinator'
        else:
            return 'element'
    
    def is_complex_selector(self, selector):
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù…Ø¹Ù‚Ø¯"""
        complexity_indicators = [
            len(selector.split()) > 2,  # Ø£ÙƒØ«Ø± Ù…Ù† Ø¹Ù†ØµØ±ÙŠÙ†
            any(op in selector for op in ['+', '>', '~']),  # combinators
            '[' in selector and ']' in selector,  # attribute selectors
            ':' in selector,  # pseudo selectors
            selector.count('.') > 2,  # Ø£ÙƒØ«Ø± Ù…Ù† ÙƒÙ„Ø§Ø³ÙŠÙ†
            selector.count('#') > 1   # Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ø¹Ø±Ù
        ]
        
        return any(complexity_indicators)
    
    def process_multiple_files(self, file_paths):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"""
        results = {}
        
        for file_path in file_paths:
            print(f"ğŸ“„ Ù…Ø¹Ø§Ù„Ø¬Ø©: {file_path}")
            
            if not os.path.exists(file_path):
                print(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}")
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(file_path, 'r', encoding='latin1') as f:
                        content = f.read()
                except Exception as e:
                    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {file_path}: {e}")
                    continue
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            file_data = self.extract_css_with_definitions(content, os.path.basename(file_path))
            results[file_path] = file_data
        
        return results
    
    def merge_duplicate_classes(self):
        """Ø¯Ù…Ø¬ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø¨Ø°ÙƒØ§Ø¡"""
        
        for class_name, definitions in self.duplicate_classes.items():
            merged_properties = OrderedDict()
            sources = []
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ¹Ø±ÙŠÙØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù€ specificity
            sorted_definitions = sorted(definitions, key=lambda x: x['specificity']['score'])
            
            for definition in sorted_definitions:
                sources.append(f"{definition['source']}:{definition['selector']}")
                
                # Ø¯Ù…Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ (Ø§Ù„Ø£Ø®ÙŠØ± ÙŠØºÙ„Ø¨)
                for prop, prop_data in definition['properties'].items():
                    merged_properties[prop] = prop_data
            
            self.merged_definitions[class_name] = {
                'merged_properties': merged_properties,
                'sources': sources,
                'total_definitions': len(definitions),
                'final_specificity': sorted_definitions[-1]['specificity']
            }
    
    def generate_comprehensive_report(self, results, output_file):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"""
        
        # Ø¯Ù…Ø¬ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        self.merge_duplicate_classes()
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        all_classes = set()
        all_ids = set()
        all_elements = set()
        
        for file_data in results.values():
            all_classes.update(file_data['classes'].keys())
            all_ids.update(file_data['ids'].keys())
            all_elements.update(file_data['elements'].keys())
        
        report = {
            'extraction_info': {
                'date': datetime.now().isoformat(),
                'total_files': len(results),
                'extractor_version': '2.0.0'
            },
            'global_statistics': {
                'unique_classes': len(all_classes),
                'unique_ids': len(all_ids),
                'unique_elements': len(all_elements),
                'duplicate_classes': len(self.duplicate_classes),
                'total_class_definitions': sum(len(defs) for defs in self.global_classes.values())
            },
            'files_analysis': {},
            'duplicate_classes_analysis': {},
            'merged_definitions': {},
            'class_hierarchy': self.build_class_hierarchy(all_classes),
            'recommendations': self.generate_recommendations()
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
        for file_path, file_data in results.items():
            report['files_analysis'][os.path.basename(file_path)] = {
                'statistics': file_data['statistics'],
                'imports': file_data['imports'],
                'classes': list(file_data['classes'].keys()),
                'ids': list(file_data['ids'].keys()),
                'elements': list(file_data['elements'].keys()),
                'has_media_queries': len(file_data['media_queries']) > 0,
                'complex_selectors_count': len(file_data['complex_selectors'])
            }
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        for class_name, definitions in self.duplicate_classes.items():
            report['duplicate_classes_analysis'][class_name] = {
                'occurrences': len(definitions),
                'sources': list(self.class_sources[class_name]),
                'different_properties': len(set(
                    str(sorted(d['properties'].keys())) for d in definitions
                )) > 1,
                'max_specificity': max(d['specificity']['score'] for d in definitions)
            }
        
        # Ø§Ù„ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
        for class_name, merged_data in self.merged_definitions.items():
            report['merged_definitions'][class_name] = {
                'sources': merged_data['sources'],
                'total_definitions': merged_data['total_definitions'],
                'properties_count': len(merged_data['merged_properties']),
                'final_specificity': merged_data['final_specificity']['score']
            }
        
        # ÙƒØªØ§Ø¨Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„: {output_file}")
        return report
    
    def build_class_hierarchy(self, classes):
        """Ø¨Ù†Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ù‡Ø±Ù…ÙŠ Ù„Ù„ÙƒÙ„Ø§Ø³Ø§Øª"""
        hierarchy = defaultdict(list)
        
        for class_name in sorted(classes):
            # ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø©
            if class_name.startswith('Page'):
                hierarchy['Page System'].append(class_name)
            elif class_name.startswith('Menu') or class_name.startswith('Navigation'):
                hierarchy['Menu & Navigation'].append(class_name)
            elif class_name.startswith('Data') or class_name.startswith('Grid') or class_name.startswith('Table'):
                hierarchy['Data Display'].append(class_name)
            elif class_name.startswith('Form') or class_name.startswith('Input') or class_name.startswith('Field'):
                hierarchy['Forms & Inputs'].append(class_name)
            elif class_name.startswith('Button') or class_name.startswith('btn'):
                hierarchy['Buttons & Actions'].append(class_name)
            elif class_name.startswith('Header') or class_name.startswith('Footer') or class_name.startswith('Layout'):
                hierarchy['Layout & Structure'].append(class_name)
            elif class_name.startswith('Modal') or class_name.startswith('Dialog') or class_name.startswith('Popup'):
                hierarchy['Modals & Dialogs'].append(class_name)
            elif class_name.startswith('Tab') or class_name.startswith('Accordion'):
                hierarchy['UI Components'].append(class_name)
            elif class_name.startswith('Login') or class_name.startswith('Member') or class_name.startswith('User'):
                hierarchy['Authentication'].append(class_name)
            else:
                hierarchy['General & Utilities'].append(class_name)
        
        return dict(hierarchy)
    
    def generate_recommendations(self):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†"""
        recommendations = []
        
        # ØªÙˆØµÙŠØ§Øª Ù„Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        if self.duplicate_classes:
            recommendations.append({
                'type': 'duplicates',
                'priority': 'high',
                'message': f'ÙŠÙˆØ¬Ø¯ {len(self.duplicate_classes)} ÙƒÙ„Ø§Ø³ Ù…ÙƒØ±Ø± ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØ¯Ù…Ø¬',
                'action': 'Ù‚Ù… Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© ÙˆØ¯Ù…Ø¬Ù‡Ø§ ÙÙŠ Ù…Ù„Ù CSS Ù…ÙˆØ­Ø¯'
            })
        
        # ØªÙˆØµÙŠØ§Øª Ù„Ù„ØªÙ†Ø¸ÙŠÙ…
        if len(self.global_classes) > 100:
            recommendations.append({
                'type': 'organization',
                'priority': 'medium',
                'message': 'Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª ÙŠØ­ØªØ§Ø¬ ØªÙ†Ø¸ÙŠÙ… Ø£ÙØ¶Ù„',
                'action': 'Ù‚Ø³Ù… Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø¥Ù„Ù‰ Ù…Ù„ÙØ§Øª Ù…Ù†ÙØµÙ„Ø© Ø­Ø³Ø¨ Ø§Ù„ÙˆØ¸ÙŠÙØ©'
            })
        
        # ØªÙˆØµÙŠØ§Øª Ù„Ù„Ø£Ø¯Ø§Ø¡
        complex_selectors = sum(
            len(data.get('complex_selectors', {})) 
            for data in [getattr(self, 'current_file_data', {})]
        )
        
        if complex_selectors > 20:
            recommendations.append({
                'type': 'performance',
                'priority': 'medium',
                'message': 'Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ù…Ø­Ø¯Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ù‚Ø¯ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡',
                'action': 'Ø¨Ø³Ø· Ø§Ù„Ù…Ø­Ø¯Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© ÙˆØ§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ø§Ø³Ø§Øª Ù…Ø¨Ø§Ø´Ø±Ø©'
            })
        
        return recommendations

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
if __name__ == "__main__":
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªØ­Ù„ÙŠÙ„ CSS...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
    extractor = AdvancedCSSExtractor()
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    css_files = [
        "App_Themes/Citrus/Citrus.css",
        "App_Themes/_Shared/_Layout.css",
        "App_Themes/_Shared/Core.css",
        "App_Themes/_Shared/Membership.css",
        "App_Themes/eZee/StyleSheet.css"
    ]
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    additional_css = []
    for pattern in ["css/*.css", "App_Themes/*/*.css"]:
        for path in Path(".").glob(pattern):
            if str(path) not in css_files:
                additional_css.append(str(path))
    
    all_files = css_files + additional_css
    
    print(f"ğŸ“ Ø³ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© {len(all_files)} Ù…Ù„Ù CSS")
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
    results = extractor.process_multiple_files(all_files)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„
    report = extractor.generate_comprehensive_report(results, "comprehensive-css-analysis.json")
    
    print(f"""
ğŸ‰ ØªÙ… Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„!

ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©: {report['global_statistics']['unique_classes']}
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª: {report['global_statistics']['unique_ids']}
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ±: {report['global_statistics']['unique_elements']}
- Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©: {report['global_statistics']['duplicate_classes']}
- Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {report['global_statistics']['total_files']}

ğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙÙ†Ø´Ø£Ø©:
- comprehensive-css-analysis.json (ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±)

ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {len(report['recommendations'])} ØªÙˆØµÙŠØ© Ù„Ù„ØªØ­Ø³ÙŠÙ†
    """)
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
    if report['global_statistics']['duplicate_classes'] > 0:
        print("\nâš ï¸  Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù‡Ù…ÙŠØ©:")
        for class_name, analysis in list(report['duplicate_classes_analysis'].items())[:5]:
            print(f"  â€¢ {class_name}: {analysis['occurrences']} ØªØ¹Ø±ÙŠÙ ÙÙŠ {len(analysis['sources'])} Ù…Ù„Ù")
